{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import ijson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the original image\n",
    "\n",
    "from torchvision.transforms.functional import resize\n",
    "\n",
    "# Load the .pt file\n",
    "image_path = 'trainA_nonorm/0be3a23f-e329a79b.pt' # the name to the corresponding pt file\n",
    "image_tensor = torch.load(image_path)  # Shape: [C, H, W]\n",
    "\n",
    "image_tensor = F.resize(image_tensor, (700, 900))  # Shape: [C, 600, 800]\n",
    "\n",
    "image_tensor = image_tensor/256\n",
    "\n",
    "# Ensure values are in [0, 1] range\n",
    "image_tensor = image_tensor.clamp(0, 1)\n",
    "\n",
    "image_tensor = image_tensor.to(torch.float32).cpu()\n",
    "\n",
    "# Ensure the shape is (H, W, C) for RGB images\n",
    "if image_tensor.dim() == 3 and image_tensor.shape[0] in [1, 3]:  \n",
    "    image_np = image_tensor.permute(1, 2, 0).numpy()\n",
    "elif image_tensor.dim() == 2:  \n",
    "    image_np = image_tensor.numpy()\n",
    "else:\n",
    "    raise ValueError(\"Unexpected tensor shape:\", image_tensor.shape)\n",
    "\n",
    "# Normalize if values are outside [0,1] (assume max 255 for images)\n",
    "if image_np.max() > 1.0:\n",
    "    image_np = image_np / 255.0  # Normalize to range [0,1]\n",
    "\n",
    "# Plot the original image\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(image_tensor.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that applys the color and brightness enhancement\n",
    "\n",
    "def contrast_stretch(image, low_percentile=0, high_percentile=85):\n",
    "    \"\"\"\n",
    "    Perform contrast stretching while printing debug info to avoid full black images.\n",
    "    \n",
    "    :param image: PyTorch tensor of shape (C, H, W)\n",
    "    :param low_percentile: Lower percentile for clipping\n",
    "    :param high_percentile: Upper percentile for clipping\n",
    "    :return: Contrast-stretched tensor\n",
    "    \"\"\"\n",
    "    image_np = image.cpu().numpy()\n",
    "    \n",
    "    # Compute percentiles\n",
    "    min_val = np.percentile(image_np, low_percentile)\n",
    "    max_val = np.percentile(image_np, high_percentile)\n",
    "    \n",
    "    print(f\"Debug: Min percentile value = {min_val}, Max percentile value = {max_val}\")\n",
    "    \n",
    "    if max_val - min_val < 1e-6:\n",
    "        print(\"Warning: Min and max values are too close! Returning original image.\")\n",
    "        return image  # Return original image to avoid black output\n",
    "    \n",
    "    # Apply contrast stretching\n",
    "    stretched = (image_np - min_val) / (max_val - min_val + 1e-8)\n",
    "    \n",
    "    # Clip values to avoid over-brightening\n",
    "    stretched = np.clip(stretched, 0, 1)\n",
    "\n",
    "    return torch.tensor(stretched, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Usage\n",
    "\n",
    "image_path = 'trainA_700nonorm/0be3a23f-e329a79b.pt' # the name to the corresponding pt file\n",
    "image_tensor = torch.load(image_path)  # Shape: [C, H, W]\n",
    "\n",
    "# Ensure the tensor is float32\n",
    "image_tensor = image_tensor.to(torch.float32)\n",
    "\n",
    "image_tensor = contrast_stretch(image_tensor)\n",
    "\n",
    "if image_np.max() > 1.0:\n",
    "    image_np = image_np / 255.0  # Normalize to range [0,1]\n",
    "\n",
    "    \n",
    "# Ensure values are in [0, 1] range\n",
    "image_tensor = image_tensor.clamp(0, 1)\n",
    "image_tensor = F.resize(image_tensor, (700, 900))  # Shape: [C, 600, 800]\n",
    "\n",
    "# Move tensor to CPU (optional)\n",
    "image_tensor = image_tensor.to(torch.float32).cpu()\n",
    "\n",
    "# # Ensure the shape is (H, W, C) for RGB images\n",
    "# if image_tensor.dim() == 3 and image_tensor.shape[0] in [1, 3]:  \n",
    "#     image_np = image_tensor.permute(1, 2, 0).numpy()\n",
    "# elif image_tensor.dim() == 2:  \n",
    "#     image_np = image_tensor.numpy()\n",
    "# else:\n",
    "#     raise ValueError(\"Unexpected tensor shape:\", image_tensor.shape)\n",
    "\n",
    "# Normalize if values are outside [0,1] (assume max 255 for images)\n",
    "\n",
    "# show the enhanced image\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(image_tensor.permute(1, 2, 0))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
