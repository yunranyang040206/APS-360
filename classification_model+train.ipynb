{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ground truth set in training\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "import ijson\n",
    "\n",
    "\n",
    "# Define transformations for the image patches\n",
    "IMAGE_SIZE = (128, 128)  # Resize patches for CNN input\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "def standardize_filename(path_or_name):\n",
    "    # Remove any directories\n",
    "    base = os.path.basename(path_or_name)\n",
    "    # Split off the first extension (e.g. \".pt\" or \".jpg\")\n",
    "    base, _ = os.path.splitext(base)\n",
    "    return base  # e.g. \"abcd123.jpg\" or just \"abcd123\" if there were two extensions\n",
    "\n",
    "def extract_first_n_labels(json_file_path, n):\n",
    "    labels = []\n",
    "    with open(json_file_path, 'rb') as f:\n",
    "        parser = ijson.items(f, 'item')\n",
    "        for i, item in enumerate(parser):\n",
    "            if i >= n:\n",
    "                break\n",
    "            filtered_labels = [\n",
    "                {\n",
    "                    \"category\": label_item.get(\"category\"),\n",
    "                    \"box2d\": label_item.get(\"box2d\")\n",
    "                }\n",
    "                for label_item in item.get(\"labels\", [])\n",
    "                if \"box2d\" in label_item\n",
    "            ]\n",
    "            labels.append({\n",
    "                \"name\": item.get(\"name\"),\n",
    "                \"timestamp\": item.get(\"timestamp\"),\n",
    "                \"labels\": filtered_labels\n",
    "            })\n",
    "    return labels\n",
    "\n",
    "class GroundTruthDataset(Dataset):\n",
    "    def __init__(self, image_dir, labels):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_files = sorted([\n",
    "            os.path.join(image_dir, f)\n",
    "            for f in os.listdir(image_dir)\n",
    "            if f.lower().endswith(('.jpg', '.png', '.jpeg'))\n",
    "        ])\n",
    "        self.label_dict = {standardize_filename(item[\"name\"]): item for item in labels}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_files[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image_width, image_height = image.size\n",
    "        base_key = standardize_filename(image_path)\n",
    "\n",
    "        matched = self.label_dict.get(base_key, None)\n",
    "        crops, labels = [], []\n",
    "\n",
    "        if matched and \"labels\" in matched:\n",
    "            for obj in matched[\"labels\"]:\n",
    "                if \"box2d\" in obj:\n",
    "                    b2d = obj[\"box2d\"]\n",
    "                    y1, x1, y2, x2 = map(int, [b2d[\"y1\"], b2d[\"x1\"], b2d[\"y2\"], b2d[\"x2\"]])\n",
    "\n",
    "                    # Ensure the box is within image boundaries\n",
    "                    y1, x1 = max(0, y1), max(0, x1)\n",
    "                    y2, x2 = min(image_height, y2), min(image_width, x2)\n",
    "\n",
    "                    # Crop and resize object patch\n",
    "                    patch = image.crop((x1, y1, x2, y2))\n",
    "                    patch = transform(patch)\n",
    "\n",
    "                    crops.append(patch)\n",
    "                    labels.append(name_to_id.get(obj[\"category\"], 0))  # Convert category name to ID\n",
    "\n",
    "        if not crops:  # If no objects found, return whole image as background\n",
    "            crops.append(transform(image))\n",
    "            labels.append(0)  # Background class\n",
    "\n",
    "        return torch.stack(crops), torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "# Class mapping (same for training & inference)\n",
    "name_to_id = {\"traffic light\": 0,\n",
    "    \"traffic sign\": 1,\n",
    "    \"car\": 2,\n",
    "    \"person\": 3,\n",
    "    \"bus\": 4,\n",
    "    \"truck\": 5,\n",
    "    \"rider\": 6,\n",
    "    \"bike\": 7,\n",
    "    \"motor\": 8,\n",
    "    \"train\": 9\n",
    "}\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    \"\"\"Custom collate function for DataLoader.\"\"\"\n",
    "    all_patches = []\n",
    "    all_labels = []\n",
    "\n",
    "    for patches, labels in batch:\n",
    "        all_patches.append(patches)  # Each image has a different number of patches\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    return all_patches, all_labels  # Keep them as lists instead of stacking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition with Dropout + freeze\n",
    "class ObjectClassifier_new(nn.Module):\n",
    "    def __init__(self, num_classes=10, dropout_p=0.5, freeze_backbone=True):\n",
    "        super(ObjectClassifier_new, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "\n",
    "        # Optionally freeze early layers\n",
    "        if freeze_backbone:\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in self.model.layer4.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in self.model.fc.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "        # Replace the classification head with dropout + linear\n",
    "        in_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_p),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (replace `ground_truth_labels` with your actual dataset labels)\n",
    "json_file_path = 'bdd100k_labels_images_train.json'\n",
    "\n",
    "# Extract labels from JSON (adjust number as desired)\n",
    "ground_truth_labels = extract_first_n_labels(json_file_path, 40000)\n",
    "\n",
    "dataset = GroundTruthDataset(image_dir= \"trainA_original_2000\", labels= ground_truth_labels)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=custom_collate_fn)\n",
    "# Split using random_split (70% train, 15% val, 15% test)\n",
    "batch_size = 4\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrast stretch on training data set\n",
    "import numpy as np\n",
    "def contrast_stretch(image, low_percentile=10, high_percentile=90):\n",
    "    \"\"\"\n",
    "    Apply contrast stretching to a single image tensor (C, H, W).\n",
    "    Returns: Tensor of same shape and type.\n",
    "    \"\"\"\n",
    "    image_np = image.cpu().numpy()\n",
    "\n",
    "    min_val = np.percentile(image_np, low_percentile)\n",
    "    max_val = np.percentile(image_np, high_percentile)\n",
    "\n",
    "    if max_val - min_val < 1e-6:\n",
    "        return image  # Avoid division by near-zero\n",
    "\n",
    "    stretched = (image_np - min_val) / (max_val - min_val + 1e-8)\n",
    "    stretched = np.clip(stretched, 0, 1)\n",
    "\n",
    "    return torch.tensor(stretched, dtype=image.dtype, device=image.device)\n",
    "\n",
    "def enhance_contrast_in_dataset(dataset, low_percentile=10, high_percentile=90):\n",
    "    \"\"\"\n",
    "    Applies contrast stretching to each cropped patch in a dataset.\n",
    "    Returns: List of (crops, labels) with contrast-enhanced tensors.\n",
    "    \"\"\"\n",
    "    enhanced_data = []\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        crops, labels = dataset[i]  # crops: [N, C, H, W]\n",
    "\n",
    "        enhanced_crops = []\n",
    "        for crop in crops:\n",
    "            enhanced = contrast_stretch(crop, low_percentile, high_percentile)\n",
    "            enhanced_crops.append(enhanced)\n",
    "\n",
    "        enhanced_data.append((torch.stack(enhanced_crops), labels))\n",
    "\n",
    "    return enhanced_data\n",
    "\n",
    "enhanced_train_dataset = enhance_contrast_in_dataset(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(enhanced_train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn, num_workers=os.cpu_count(), pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn, num_workers=os.cpu_count(), pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn, num_workers=os.cpu_count(), pin_memory=True)\n",
    "\n",
    "print (f\"Train size: {len(train_loader.dataset)}\")\n",
    "print (f\"Val size: {len(val_loader.dataset)}\")\n",
    "print (f\"Test size: {len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For tracking loss curves\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "best_val_loss = 0.1\n",
    "\n",
    "# Best validation loss (init high)\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ObjectClassifier_new(num_classes=len(name_to_id)).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Set CPU parallelism (for data loading)\n",
    "torch.set_num_threads(os.cpu_count())\n",
    "\n",
    "# Enable mixed precision (for speedup on GPUs)\n",
    "scaler = torch.amp.GradScaler()\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.1, patience=2, verbose=True\n",
    ")\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "early_stop_patience = 10\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for batch_patches, batch_labels in train_loader:  # Each batch is a list of patch tensors\n",
    "        batch_loss = 0\n",
    "\n",
    "        batch_patches = [patches.to(device) for patches in batch_patches]\n",
    "        batch_labels = [labels.to(device) for labels in batch_labels]\n",
    "        for patches, labels in zip(batch_patches, batch_labels):\n",
    "            outputs = model(patches)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(patches)\n",
    "            loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # validation\n",
    "    total_val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_patches, val_labels in val_loader:\n",
    "            val_patches = [patches.to(device) for patches in val_patches]\n",
    "            val_labels = [labels.to(device) for labels in val_labels]\n",
    "            for patches, labels in zip(val_patches, val_labels):\n",
    "              outputs = model(patches)\n",
    "\n",
    "              optimizer.zero_grad()\n",
    "              outputs = model(patches)\n",
    "              loss = criterion(outputs, labels)\n",
    "\n",
    "              total_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    # scheduler step + early stopping\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(\"Saved best model!\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= early_stop_patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "\n",
    "    ### === EPOCH SUMMARY === ###\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot test and val loss graphs\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision calculation on training and validation data\n",
    "from sklearn.metrics import precision_score\n",
    "model_test = ObjectClassifier_new(num_classes=len(name_to_id)).to(device)\n",
    "model_test.load_state_dict(torch.load(\"best_model.pth\",map_location=device))\n",
    "\n",
    "model_test.eval()  # Set model to evaluation mode\n",
    "\n",
    "\n",
    "print(\"🔍 Sample Predictions on Train Data:\\n\")\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (train_patches, train_labels) in enumerate(train_loader):\n",
    "        train_patches_tensor = torch.cat(train_patches, dim=0).to(device)\n",
    "        train_labels_tensor = torch.cat(train_labels, dim=0).to(device)\n",
    "\n",
    "        outputs = model_test(train_patches_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Save for precision calculation\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(train_labels_tensor.cpu().numpy())\n",
    "\n",
    "        if i < 2:\n",
    "            for j in range(min(len(predicted), 10)):\n",
    "                print(f\"Sample {j+1}: Predicted = {predicted[j].item()}, Actual = {train_labels_tensor[j].item()}\")\n",
    "\n",
    "# Calculate precision (macro-averaged across all classes)\n",
    "precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "print(f\"\\n🎯 Train Precision (Macro): {precision * 100:.2f}%\")\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "\n",
    "print(\"🔍 Sample Predictions on Validation Data:\\n\")\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (val_patches, val_labels) in enumerate(val_loader):\n",
    "        val_patches_tensor = torch.cat(val_patches, dim=0).to(device)\n",
    "        val_labels_tensor = torch.cat(val_labels, dim=0).to(device)\n",
    "\n",
    "        outputs = model_test(val_patches_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Save for precision calculation\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(val_labels_tensor.cpu().numpy())\n",
    "\n",
    "        if i < 2:\n",
    "            for j in range(min(len(predicted), 10)):\n",
    "                print(f\"Sample {j+1}: Predicted = {predicted[j].item()}, Actual = {val_labels_tensor[j].item()}\")\n",
    "\n",
    "# Calculate precision (macro-averaged across all classes)\n",
    "precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "print(f\"\\n🎯 Validation Precision (Macro): {precision * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision calculation on test data\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "\n",
    "print(\"🔍 Sample Predictions on Test Data:\\n\")\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (test_patches, test_labels) in enumerate(test_loader):\n",
    "        test_patches_tensor = torch.cat(test_patches, dim=0).to(device)\n",
    "        test_labels_tensor = torch.cat(test_labels, dim=0).to(device)\n",
    "\n",
    "        outputs = model_test(test_patches_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Save for precision calculation\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(test_labels_tensor.cpu().numpy())\n",
    "\n",
    "        if i < 2:\n",
    "            for j in range(min(len(predicted), 10)):\n",
    "                print(f\"Sample {j+1}: Predicted = {predicted[j].item()}, Actual = {test_labels_tensor[j].item()}\")\n",
    "\n",
    "# Calculate precision (macro-averaged across all classes)\n",
    "precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "print(f\"\\n🎯 Test Precision (Macro): {precision * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
